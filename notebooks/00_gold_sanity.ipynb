{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f67664e-ce91-4f54-bb39-c81ab499288e",
   "metadata": {},
   "source": [
    "## NB “gold sanity” para comprobar:\n",
    "- qué gold real se está usando ene experimentos,\n",
    "- qué tipo de offsets trae (char vs token),\n",
    "- si los spans cuadran con el texto del gold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d529dd-d296-475f-8e34-d694d500265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Celda 1 — Imports base\n",
    "from pathlib import Path\n",
    "import json, re\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff26c9d-d021-4873-a51b-61f5b7e4bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /home/jovyan/inesagent\n",
      "/home/jovyan/inesagent/gold/corpus_annotated.jsonl -> True\n",
      "/home/jovyan/inesagent/outputs/splits/val_gold.jsonl -> True\n",
      "/home/jovyan/inesagent/outputs/splits/test_gold.jsonl -> True\n",
      "/home/jovyan/inesagent/outputs/splits/train_gold.jsonl -> True\n",
      "/home/jovyan/inesagent/outputs/splits/prompt_regression_gold.jsonl -> True\n",
      "/home/jovyan/inesagent/outputs/memory/memory_selected_FINAL.json -> True\n",
      "/home/jovyan/inesagent/outputs/memory/blocked_doc_uids_by_memory.json -> True\n"
     ]
    }
   ],
   "source": [
    "#Celda 2 — Paths del proyecto (tu estructura actual) - carpeta maestra /home/jovyan/inesagent\n",
    "ROOT = Path.home() / \"inesagent\"\n",
    "assert ROOT.exists(), f\"ROOT no existe: {ROOT}\"\n",
    "print(\"ROOT:\", ROOT)\n",
    "\n",
    "# GOLD (anotado)\n",
    "PATH_GOLD = ROOT / \"gold\" / \"corpus_annotated.jsonl\"   # si fuera .json, lo cambiamos\n",
    "\n",
    "# Splits (los que estás usando ahora)\n",
    "SPLITS_DIR = ROOT / \"outputs\" / \"splits\"\n",
    "PATH_VAL   = SPLITS_DIR / \"val_gold.jsonl\"\n",
    "PATH_TEST  = SPLITS_DIR / \"test_gold.jsonl\"\n",
    "PATH_TRAIN = SPLITS_DIR / \"train_gold.jsonl\"\n",
    "PATH_PR    = SPLITS_DIR / \"prompt_regression_gold.jsonl\"\n",
    "\n",
    "# (Opcional) memoria y bloqueados, por si quieres comparar doc_uids\n",
    "PATH_MEMORY  = ROOT / \"outputs\" / \"memory\" / \"memory_selected_FINAL.json\"\n",
    "PATH_BLOCKED = ROOT / \"outputs\" / \"memory\" / \"blocked_doc_uids_by_memory.json\"\n",
    "\n",
    "for p in [PATH_GOLD, PATH_VAL, PATH_TEST, PATH_TRAIN, PATH_PR, PATH_MEMORY, PATH_BLOCKED]:\n",
    "    print(str(p), \"->\", p.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9188427-134b-4a20-b95a-f86ccb30c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Celda 3 — Utilidades de carga\n",
    "def load_json(path: Path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_jsonl(path: Path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b14a932-de9d-4aa9-a50a-33a02094f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: 34\n",
      "test: 34\n",
      "train: 279\n",
      "prompt_reg: 10\n",
      "keys val[0]: dict_keys(['doc_uid', 'text'])\n"
     ]
    }
   ],
   "source": [
    "#Celda 4 — Cargar splits\n",
    "val_docs  = load_jsonl(PATH_VAL) if PATH_VAL.exists() else []\n",
    "test_docs = load_jsonl(PATH_TEST) if PATH_TEST.exists() else []\n",
    "train_docs = load_jsonl(PATH_TRAIN) if PATH_TRAIN.exists() else []\n",
    "pr_docs   = load_jsonl(PATH_PR) if PATH_PR.exists() else []\n",
    "\n",
    "print(\"val:\", len(val_docs))\n",
    "print(\"test:\", len(test_docs))\n",
    "print(\"train:\", len(train_docs))\n",
    "print(\"prompt_reg:\", len(pr_docs))\n",
    "\n",
    "print(\"keys val[0]:\", val_docs[0].keys() if val_docs else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0674f61-03d4-420d-b2da-e47f8f24387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_all: 373\n",
      "keys gold_all[0]: dict_keys(['id', 'text', 'tags'])\n",
      "unique doc_uids in gold: 0\n"
     ]
    }
   ],
   "source": [
    "#Celda 5 — Cargar GOLD completo e indexar por doc_uid\n",
    "gold_all = load_jsonl(PATH_GOLD)\n",
    "print(\"gold_all:\", len(gold_all))\n",
    "print(\"keys gold_all[0]:\", gold_all[0].keys())\n",
    "\n",
    "gold_by_uid = {d[\"doc_uid\"]: d for d in gold_all if \"doc_uid\" in d}\n",
    "print(\"unique doc_uids in gold:\", len(gold_by_uid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39f1243-6c2b-4cd8-bd4f-21b1138a02dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val uids in gold: 0 / 34\n",
      "test uids in gold: 0 / 34\n",
      "train uids in gold: 0 / 279\n",
      "pr uids in gold: 0 / 10\n"
     ]
    }
   ],
   "source": [
    "#Celda 6 — ¿Los doc_uids del split existen en el gold?\n",
    "def uids(docs):\n",
    "    return {d[\"doc_uid\"] for d in docs if \"doc_uid\" in d}\n",
    "\n",
    "u_val, u_test, u_train, u_pr = map(uids, [val_docs, test_docs, train_docs, pr_docs])\n",
    "\n",
    "print(\"val uids in gold:\", sum(uid in gold_by_uid for uid in u_val), \"/\", len(u_val))\n",
    "print(\"test uids in gold:\", sum(uid in gold_by_uid for uid in u_test), \"/\", len(u_test))\n",
    "print(\"train uids in gold:\", sum(uid in gold_by_uid for uid in u_train), \"/\", len(u_train))\n",
    "print(\"pr uids in gold:\", sum(uid in gold_by_uid for uid in u_pr), \"/\", len(u_pr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74336c40-4498-4a88-a3af-6be22aa78319",
   "metadata": {},
   "source": [
    "**Si `0`, significa NO están en gold, estamos usando un split que no corresponde al gold que creemos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a09651e1-a16c-4d41-b1cd-9dc43a8cbe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID no está en gold: e65775141ab5c82bd0bd1f89e4873090c43a9569\n"
     ]
    }
   ],
   "source": [
    "#Celda 7 — Inspección manual de un doc (texto + spans gold)\n",
    "def show_gold(uid: str, n=10, context=40):\n",
    "    d = gold_by_uid.get(uid)\n",
    "    if not d:\n",
    "        print(\"UID no está en gold:\", uid)\n",
    "        return\n",
    "    text = d.get(\"text\",\"\")\n",
    "    spans = d.get(\"spans\", [])\n",
    "    print(\"uid:\", uid)\n",
    "    print(\"len(text):\", len(text))\n",
    "    print(\"n_spans:\", len(spans))\n",
    "    print(\"keys span example:\", spans[0].keys() if spans else None)\n",
    "\n",
    "    for sp in spans[:n]:\n",
    "        label = sp.get(\"label\") or sp.get(\"tag\")\n",
    "        s = sp.get(\"start\"); e = sp.get(\"end\")\n",
    "        ts = sp.get(\"token_start\"); te = sp.get(\"token_end\")\n",
    "        quote = sp.get(\"quote\")\n",
    "\n",
    "        print(\"\\nlabel:\", label, \"start:\", s, \"end:\", e, \"| token_start:\", ts, \"token_end:\", te)\n",
    "        if isinstance(s, int) and isinstance(e, int) and 0 <= s < e <= len(text):\n",
    "            print(\"text[start:end] == quote?\", (text[s:e] == quote))\n",
    "            print(\"text slice:\", repr(text[s:e])[:200])\n",
    "        else:\n",
    "            print(\"char offsets no válidos o no presentes\")\n",
    "        if isinstance(quote, str):\n",
    "            print(\"quote:\", repr(quote)[:200])\n",
    "\n",
    "# ejemplo con tu uid problemático:\n",
    "show_gold(\"e65775141ab5c82bd0bd1f89e4873090c43a9569\", n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4261239e-fe40-4d63-9734-803377a0e16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT val ejemplo uid: ddfd9d0d476258da87bc3add8c5e286f010c6234\n",
      "SPLIT val ejemplo keys: dict_keys(['doc_uid', 'text'])\n",
      "SPLIT val texto len: 12095\n",
      "GOLD ejemplo id: 942034809\n",
      "GOLD ejemplo keys: dict_keys(['id', 'text', 'tags'])\n",
      "GOLD texto len: 7085\n"
     ]
    }
   ],
   "source": [
    "#Celda A — mira 1 doc_uid de cada cosa\n",
    "print(\"SPLIT val ejemplo uid:\", val_docs[0][\"doc_uid\"])\n",
    "print(\"SPLIT val ejemplo keys:\", val_docs[0].keys())\n",
    "print(\"SPLIT val texto len:\", len(val_docs[0].get(\"text\",\"\")))\n",
    "\n",
    "print(\"GOLD ejemplo id:\", gold_all[0][\"id\"])\n",
    "print(\"GOLD ejemplo keys:\", gold_all[0].keys())\n",
    "print(\"GOLD texto len:\", len(gold_all[0].get(\"text\",\"\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d326c8-b869-40b8-8855-b856a5ddc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Celda B — define normalización mínima + hash\n",
    "import hashlib, re\n",
    "\n",
    "def norm_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)          # colapsa espacios\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)       # colapsa saltos excesivos\n",
    "    return s.strip()\n",
    "\n",
    "def sha1_str(s: str) -> str:\n",
    "    return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b5f98a-4562-4946-b3d3-4f70cd7b94c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_by_hash size: 373 collisions: 0\n"
     ]
    }
   ],
   "source": [
    "#Celda C — indexa el gold por hash del texto\n",
    "gold_by_hash = {}\n",
    "collisions = 0\n",
    "\n",
    "for d in gold_all:\n",
    "    t = d.get(\"text\",\"\")\n",
    "    h = sha1_str(norm_text(t))\n",
    "    if h in gold_by_hash:\n",
    "        collisions += 1\n",
    "    else:\n",
    "        gold_by_hash[h] = d\n",
    "\n",
    "print(\"gold_by_hash size:\", len(gold_by_hash), \"collisions:\", collisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3db9d8-7219-4d43-a183-4f03755b741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val match: (34, 34)\n",
      "test match: (34, 34)\n",
      "train match: (279, 279)\n",
      "pr match: (10, 10)\n"
     ]
    }
   ],
   "source": [
    "#Celda D — comprueba cuánto “match” hay ahora\n",
    "def match_rate(split_docs):\n",
    "    hits = 0\n",
    "    for d in split_docs:\n",
    "        h = sha1_str(norm_text(d.get(\"text\",\"\")))\n",
    "        if h in gold_by_hash:\n",
    "            hits += 1\n",
    "    return hits, len(split_docs)\n",
    "\n",
    "print(\"val match:\", match_rate(val_docs))\n",
    "print(\"test match:\", match_rate(test_docs))\n",
    "print(\"train match:\", match_rate(train_docs))\n",
    "print(\"pr match:\", match_rate(pr_docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35189de5-4983-4287-8f8d-251e19cf34ec",
   "metadata": {},
   "source": [
    "**Si ahora  sale 34/34, 279/279, etc. → perfecto: era doc_uid distinto, pero el texto es el mismo.**\n",
    "\n",
    "Ahora, reconstruimos splits “bien”\n",
    "\n",
    "La idea: crear nuevos splits que usen el `doc_uid` del gold (el “oficial”) y opcionalmente incluyan spans gold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c11ba078-6d22-4609-9202-9562f70613f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /home/jovyan/inesagent/outputs/splits/val_gold_FIXED.jsonl | fixed: 34 | missing: 0\n",
      "saved: /home/jovyan/inesagent/outputs/splits/test_gold_FIXED.jsonl | fixed: 34 | missing: 0\n",
      "saved: /home/jovyan/inesagent/outputs/splits/train_gold_FIXED.jsonl | fixed: 279 | missing: 0\n",
      "saved: /home/jovyan/inesagent/outputs/splits/prompt_regression_gold_FIXED.jsonl | fixed: 10 | missing: 0\n"
     ]
    }
   ],
   "source": [
    "#Celda E — reconstruir val_gold_fixed.jsonl (doc_uid gold + spans) y normalizar keys (etiquetas)\n",
    "def rebuild_split_gold_schema(split_docs, out_path: Path, keep_legacy_uid=True):\n",
    "    fixed = []\n",
    "    missing = 0\n",
    "\n",
    "    for d in split_docs:\n",
    "        t = d.get(\"text\",\"\")\n",
    "        h = sha1_str(norm_text(t))\n",
    "        g = gold_by_hash.get(h)\n",
    "        if not g:\n",
    "            missing += 1\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"id\": g[\"id\"],\n",
    "            \"text\": g.get(\"text\", t),\n",
    "            \"tags\": g.get(\"tags\", []),\n",
    "        }\n",
    "        if keep_legacy_uid and \"doc_uid\" in d:\n",
    "            row[\"legacy_doc_uid\"] = d[\"doc_uid\"]\n",
    "\n",
    "        fixed.append(row)\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in fixed:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(\"saved:\", out_path, \"| fixed:\", len(fixed), \"| missing:\", missing)\n",
    "\n",
    "rebuild_split_gold_schema(val_docs,   SPLITS_DIR / \"val_gold_FIXED.jsonl\")\n",
    "rebuild_split_gold_schema(test_docs,  SPLITS_DIR / \"test_gold_FIXED.jsonl\")\n",
    "rebuild_split_gold_schema(train_docs, SPLITS_DIR / \"train_gold_FIXED.jsonl\")\n",
    "rebuild_split_gold_schema(pr_docs,    SPLITS_DIR / \"prompt_regression_gold_FIXED.jsonl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e43d0f99-ea76-4b34-8cf4-515fda19b1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'text', 'tags', 'legacy_doc_uid'])\n",
      "id: -844396723\n",
      "len(text): 12095\n",
      "n_tags: 19\n",
      "tag example keys: dict_keys(['end', 'start', 'tag', 'token_end', 'token_start'])\n"
     ]
    }
   ],
   "source": [
    "val_fixed = load_jsonl(SPLITS_DIR / \"val_gold_FIXED.jsonl\")\n",
    "print(val_fixed[0].keys())\n",
    "print(\"id:\", val_fixed[0][\"id\"])\n",
    "print(\"len(text):\", len(val_fixed[0][\"text\"]))\n",
    "print(\"n_tags:\", len(val_fixed[0].get(\"tags\", [])))\n",
    "print(\"tag example keys:\", val_fixed[0][\"tags\"][0].keys() if val_fixed[0].get(\"tags\") else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e2d3493-5ce8-408d-a8cd-d44d8ae327dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits raw: 3 / 3\n",
      "hits norm: 3 / 3\n"
     ]
    }
   ],
   "source": [
    "# crea sets de posibles uids del gold\n",
    "gold_uids_raw = set()\n",
    "gold_uids_norm = set()\n",
    "\n",
    "for d in gold_all:\n",
    "    t = d.get(\"text\",\"\")\n",
    "    gold_uids_raw.add(sha1_str(t))\n",
    "    gold_uids_norm.add(sha1_str(norm_text(t)))\n",
    "\n",
    "def check_list(uids):\n",
    "    uids = [str(x) for x in uids]\n",
    "    raw_hits = sum(u in gold_uids_raw for u in uids)\n",
    "    norm_hits = sum(u in gold_uids_norm for u in uids)\n",
    "    print(\"hits raw:\", raw_hits, \"/\", len(uids))\n",
    "    print(\"hits norm:\", norm_hits, \"/\", len(uids))\n",
    "\n",
    "uids_example = [\n",
    "  \"03679c6d5ffc04910dbe34a0c3ed3c8d64d5153d\",\n",
    "  \"2a905a8059700b76f9e1084984e9ebb9d5189946\",\n",
    "  \"ff6902a21184bc2a551abc0fd538f81c838463e8\"\n",
    "]\n",
    "check_list(uids_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334cb504-a667-4e6e-8b16-376ea50d0c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inesagent_gpu (NFS /home/jovyan)",
   "language": "python",
   "name": "inesagent_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
